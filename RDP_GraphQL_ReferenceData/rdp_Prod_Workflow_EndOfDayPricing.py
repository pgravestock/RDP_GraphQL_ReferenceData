# The purpose of this module is to:

#    o load a csv file of quote PermIDs into a list, 
#    o select the end of day data graphQL query return the results as a json file.

# The QueryType varible is set to 'Pricing' - the contents of this variable is used in rdp_Common_Lib.SendGraphQLRequest to
# determine how to build the Query Variables arguments - a TimeSeries request needs a date or date range to be supplied. This
# script only supports a single price date, as a date range is outside the scope of what this script is intended for.
#
# The PriceDate variable contains the price date that the user wants to retrieve in the format Dyyyy-mm-dd format.

# The script tracks the progess of all all GraphQL API calls and writes a detailed log report in the ./Logs diretory a
# a json file, and a simpler csv file to allow the user to observe any errors that were returned by either Symbology or graphQL API. The log
# files allow the user to monitor overall performance of the different API calls, however it should be noted that the timers used to calculate 
# the run times are based on when the response has been downloaded to the users PC - in the case of large json response files, this can distort
# the reported run times vs actual run times on the APIs.
 
# The path / file name of the Quote list to be processed is stored in the Portfolio variable below. This script is currently
# configured to expect this list to contain a list of Quote PermIDs, rather than identifiers that must be converted to Quote PermIDs
# As such, it does not use the Symbology API

# Version 1.0 Initial version

import rdp_Common_Lib
import json
import csv
from datetime import datetime

Quote=[]

# The Instrument List being processed
Portfolio="./Input/EquityQuotes_20_List.csv"
QueryType="Pricing"
PriceDate="D2021-05-21"

# The graphQl query used for End of Day Pricing
ETSEoDPricingQuery="./gql_Queries/gql_End_Of_Day_Pricing.gql"

#Batch Sizes for each query.
QuoteChunkSize=5   #ETS batch size

# GraphQL Query Paths.

# The variable BatchIdentifier acts as a unique identifier that is embedded into all file outputs genrated when the script is run. The scrips generates
# the following files, so being able to determine which files are related to a specific run of the script is useful:

#    o the response of each graphQL query
#    o the json log file generated by this script that summarises the success or failire of each symbology and graphQL API call
#    o the csv log file that summarises the json log file

BatchIdentifier=datetime.now().strftime("%Y%m%d-%H%M%S")

# load the users portflio (instrument list) into a list
with open(Portfolio, mode='r', encoding='utf-8-sig') as f:
    reader=csv.reader(f)
    QuoteList=list(reader)

for row in QuoteList:
    Quote.append(row[0])

# These are the structures that will contain the symbology and graphQL logs to detail the run time of the entire request
RequestLog={}
ErrorsLog={}
GraphQLSummary=[]

#Now make the graphQL requests

queryObjectType="Quote"
graphQLLog = rdp_Common_Lib.SendGraphQLRequest(queryObjectType,QueryType,PriceDate,QuoteChunkSize,ETSEoDPricingQuery,Quote,BatchIdentifier)
for items in graphQLLog:
    objectType=items['objectType']
    objectCount=items['objectCount']
    chunkSize=items['chunkSize']
    totalGraphQLRunTimeForObjectType=items['totalGraphQLRunTimeForObjectType']
    graphQLBatches=items['batches']

    GraphQLSummary.append({
        "objectType": objectType,
        "objectCount": objectCount,
        "chunkSize": chunkSize,
        "totalGraphQLRunTimeForObjectType":totalGraphQLRunTimeForObjectType,
        "graphQLBatches": graphQLBatches
    })

RequestLog['data']=[]
RequestLog['data'].append({
    "graphQL": GraphQLSummary
})

OutputFile="./Logs/GraphQL_Log_"+ BatchIdentifier +".json"
print(f"Log output to : {OutputFile}\n")
with open(OutputFile,"w") as outFile:
    json.dump(RequestLog,outFile,indent=4)
outFile.close

rdp_Common_Lib.log_file_conversion(RequestLog, BatchIdentifier)

print(f"\nProcessing Complete - Check ./Logs for log details of this request, and ./Output for all output files.\n")
#====

